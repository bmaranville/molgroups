{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 21:14:39.648429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# See https://keras.io/\n",
    "# for extennsive documentation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import sklearn.utils\n",
    "\n",
    "import pickle\n",
    "def fnSaveObject(save_object, sFileName):\n",
    "    with open(sFileName, \"wb\") as file:\n",
    "        pickle.dump(save_object, file)\n",
    "\n",
    "def fnLoadObject(sFileName):\n",
    "    with open(sFileName, 'rb') as file:\n",
    "        load_object = pickle.load(file)\n",
    "    return load_object\n",
    "\n",
    "# sans_models = ['core_shell_cylinder', 'core_shell_ellipsoid', 'three_pearl_necklace', 'lamellar']\n",
    "sans_models = ['core_shell_cylinder', 'core_shell_cylinder', 'core_shell_cylinder', 'core_shell_cylinder']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_shell_cylinder\n",
      "core_shell_cylinder\n",
      "core_shell_cylinder\n",
      "core_shell_cylinder\n"
     ]
    }
   ],
   "source": [
    "# data preparation\n",
    "def y_encode(model, ydata, modellist, ydim):\n",
    "    def onehot(y_cl, num_classes):\n",
    "        y = numpy.zeros((len(y_cl), num_classes))\n",
    "        y[numpy.arange(len(y_cl)), y_cl] = 1\n",
    "        return y\n",
    "\n",
    "    result = []\n",
    "    class_number = None\n",
    "    for i, modelname in enumerate(modellist):\n",
    "        # regression outputs\n",
    "        if model == modelname:\n",
    "            # fill output for particular model with training values\n",
    "            result.append(ydata)\n",
    "            class_number = i\n",
    "        else:\n",
    "            # the outputs for the other models are set to zero\n",
    "            result.append(numpy.zeros(shape=(ydata.shape[0], ydim[i])))\n",
    "\n",
    "    # classification output, one-hot encoding for the particular model\n",
    "    oh = numpy.full((ydata.shape[0]), class_number)\n",
    "    oh = onehot(oh, len(modellist))\n",
    "    result.append(oh)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# step-by-step model loading and data augmentation\n",
    "data_x_pandas = []\n",
    "data_y_pandas = []\n",
    "data_x = None\n",
    "data_y = None\n",
    "ydim = []\n",
    "for sansmodel in sans_models:\n",
    "    print(sansmodel)\n",
    "    data_x_pandas.append(fnLoadObject('train_'+sansmodel+'_x.dat'))\n",
    "    data_y_pandas.append(fnLoadObject('train_'+sansmodel+'_y.dat'))\n",
    "    # number of parameters knowing that scale and sld_solvent will be dropped\n",
    "    ydim.append(data_y_pandas[-1][0].shape[0]-2)\n",
    "\n",
    "\n",
    "for i, sansmodel in enumerate(sans_models):\n",
    "    parlist = data_y_pandas[i][0]['par'].values.tolist()\n",
    "    modparlist = []\n",
    "    for par in parlist:\n",
    "        if 'sld' in par and par != 'sld_solvent':\n",
    "            modparlist.append(par)\n",
    "\n",
    "    for frame in data_y_pandas[i]:\n",
    "        solvent_sld = frame.loc[frame.par =='sld_solvent', 'value'].squeeze()\n",
    "\n",
    "        # reduce all sld values in the model to their difference to the solvent sld\n",
    "        for par in modparlist:\n",
    "            sld = frame.loc[frame.par == par, 'value'].squeeze()\n",
    "            frame.loc[frame.par == par, 'value'] = solvent_sld - sld\n",
    "\n",
    "        # remove solvent sld and scale factor, since they cannot be resolved\n",
    "        index_names = frame[ frame['par'] == 'scale'].index\n",
    "        frame.drop(index_names, inplace = True)\n",
    "        index_names = frame[ frame['par'] == 'sld_solvent'].index\n",
    "        frame.drop(index_names, inplace = True)\n",
    "\n",
    "    new_x = numpy.row_stack([frame['I'].to_numpy() for frame in data_x_pandas[i]]).astype('float32')\n",
    "    new_x = numpy.log10(new_x)\n",
    "    new_y = numpy.row_stack([frame['value'].to_numpy() for frame in data_y_pandas[i]]).astype('float32')\n",
    "    new_y = y_encode(sansmodel, new_y, sans_models, ydim)\n",
    "\n",
    "    if data_x is None:\n",
    "        data_x = new_x\n",
    "    else:\n",
    "        data_x = numpy.concatenate((data_x, new_x), axis=0)\n",
    "\n",
    "    if data_y is None:\n",
    "        data_y = new_y\n",
    "    else:\n",
    "        for j in range(len(sans_models)+1):\n",
    "            data_y[j] = numpy.concatenate((data_y[j], new_y[j]), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 22:00:51.447660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# model construction\n",
    "input_dim = data_x.shape[1]\n",
    "n_input_layers = 4\n",
    "n_branch_layers = 4\n",
    "output_layers = []\n",
    "\n",
    "node_n = input_dim\n",
    "\n",
    "activation = \"relu\"\n",
    "reg_strategy = keras.regularizers.l1_l2(l1=0.001, l2=0.001)  # use L1 and L2 regularization\n",
    "\n",
    "# common input layers\n",
    "sans_input = keras.Input(shape=(input_dim, ))\n",
    "x = layers.Dense(node_n, activation=activation, kernel_regularizer=reg_strategy)(sans_input)\n",
    "for _ in range(n_input_layers-1):\n",
    "    x = layers.Dense(node_n, activation=activation, kernel_regularizer=reg_strategy)(x)\n",
    "\n",
    "# split into different model regression layers plus classification\n",
    "# regression\n",
    "for j, sans_model in enumerate(sans_models):\n",
    "    x2 = layers.Dense(node_n, activation=activation, kernel_regularizer=reg_strategy)(x)\n",
    "    for i in range(n_branch_layers-1):\n",
    "        x2 = layers.Dense(node_n, activation=activation, kernel_regularizer=reg_strategy)(x2)\n",
    "    output_layers.append(Dense(data_y[j].shape[1], activation=\"linear\")(x2))\n",
    "\n",
    "# classification\n",
    "x2 = layers.Dense(node_n, activation=activation, kernel_regularizer=reg_strategy)(x)\n",
    "for _ in range(n_branch_layers-1):\n",
    "    x2 = layers.Dense(node_n, activation=activation, kernel_regularizer=reg_strategy)(x2)\n",
    "output_layers.append(Dense(len(sans_models), activation=\"softmax\")(x2))\n",
    "\n",
    "#model\n",
    "model = keras.Model(\n",
    "    inputs=[sans_input],\n",
    "    outputs=output_layers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fn_regression_loss(y_true, y_pred):\n",
    "    rank = tf.rank(y_true)\n",
    "    if rank == 2:\n",
    "        pattern = tf.zeros_like(y_true[0])\n",
    "        shape = y_true.shape[1]\n",
    "        mask = tf.math.equal(y_true, pattern)\n",
    "        split = tf.split(mask, num_or_size_splits=shape, axis=1)\n",
    "    else:\n",
    "        # unsure this function will ever get a one-dimensional vector\n",
    "        pattern = tf.zeros_like(y_true)\n",
    "        shape = y_true.shape[0]\n",
    "        mask = tf.math.equal(y_true, pattern)\n",
    "        split = tf.split(mask, num_or_size_splits=shape, axis=0)\n",
    "\n",
    "    y_mult = split[0]\n",
    "    for i in range(1, shape):\n",
    "        y_mult = tf.math.logical_and(y_mult, split[i])\n",
    "    y_mult = tf.where(y_mult, 0., 1.)\n",
    "\n",
    "    mse = tf.reduce_mean((tf.squeeze(y_pred)-tf.squeeze(y_true))**2, axis=1)\n",
    "    mse_masked = tf.math.multiply(tf.squeeze(mse), tf.squeeze(y_mult))\n",
    "    result = tf.reduce_mean(mse_masked)\n",
    "\n",
    "    return result\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "losslist = [fn_regression_loss] * len(sans_models)\n",
    "losslist.append(keras.losses.CategoricalCrossentropy)\n",
    "\n",
    "model.compile(optimizer=opt, loss=losslist)\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
